{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4f41fd-047c-47ba-8d3d-9e70deda9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Datacenter Computing team (alexghergh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca297292-08e4-4b7b-adcf-7b2d2348a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, LlamaConfig, LlamaForCausalLM\n",
    "import multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "\n",
    "torch.set_printoptions(precision=5, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72245c-3289-43f1-a36c-c68f1cc2fdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f5a4b7-aabb-41f8-b928-655a705662e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to run this on fep, using the ucsx queue\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c767ee1-0897-4e38-a4d7-0887064e9b91",
   "metadata": {},
   "source": [
    "## For this lab, we'll try to train the same model we used in the last laboratory, but in a distributed fashion. In short, distributed simply means \"more than 1 GPU\". Although there are multiple parallelism schemas, we'll only use **data parallelism** (DP) for now, to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138020f-8d55-4096-a037-4e44c5bd6297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad2cf5b-13f8-42bf-87d9-95e95e213f4f",
   "metadata": {},
   "source": [
    "## 1. The dataset, tokenizer, model, loss function, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe698b-9b15-419e-b6dc-8b902e4979af",
   "metadata": {},
   "source": [
    "We'll use the same settings from last time. Keep in mind, we want nothing more than to train the same model, on the same dataset, but in a **distributed** setup. Nothing changes, except the way the data is exchanged during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c987e1-3bd1-475e-a46e-975b9fd41606",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('roneneldan/tinystories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadd4df3-7abc-41b7-ac32-eaba050d44ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15ef51b-268d-4f6f-bacb-68ce7c4041d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f113b6f7-940d-42ae-af7c-f4f5be860829",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8bc2c63-ecf9-493f-a985-e2fb4925bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and chunk the dataset into equal pieces\n",
    "def tokenize_and_chunk(examples):\n",
    "    outputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_and_chunk, batched=True, remove_columns=ds[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c79004-26f8-4704-b680-e9cf398335bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to set the format of the dataset to \"torch\", meaning we'll use pytorch tensors\n",
    "tokenized_ds.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b81a35-2ec3-4ee6-8f5e-79e4ada9ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(50257, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (act_fn): NewGELUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((768,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((768,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((768,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same llama example model as last time\n",
    "config = LlamaConfig(vocab_size=len(tokenizer),\n",
    "                     hidden_size=768,\n",
    "                     intermediate_size=4*768,\n",
    "                     num_hidden_layers=4,\n",
    "                     num_attention_heads=16,\n",
    "                     hidden_act='gelu_new',\n",
    "                    )\n",
    "model = LlamaForCausalLM(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67733ef-07fd-4498-9b71-fc8df5272763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37755648"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters()) - 2 * len(tokenizer) * 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c362c1b0-2dfa-4805-a8df-a141a1bae6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c70c695e-7fbd-4281-b55a-ce8972bef174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.95)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0005\n",
       "    maximize: False\n",
       "    weight_decay: 0.1\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1, betas=(0.9, 0.95))\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8260a-2e2a-43b7-ba98-386ee5fb8514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ba7a211-d9ce-4923-8b51-636693937a41",
   "metadata": {},
   "source": [
    "## 2. The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cac2b-2742-4394-9474-97bd70e48d35",
   "metadata": {},
   "source": [
    "Nothing much changes here, except the synchronization of gradients. Notice the extra lines of code we used to do this.\n",
    "\n",
    "There's one extra thing that comes with parallelism, and that is the _data_ in _data parallelism_. Specifically, we also now need to partition the data for each GPU. Instead of 1 GPU seeing all the data, now 2 GPUs see half of the data (this is why the overall process should be twice faster). To do this, we simply select a subset of the data from the whole dataset, based on the rank of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6eb53cf-6e79-4faf-82f3-44194fcd0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_fn(rank, world_size):\n",
    "\n",
    "    # let's move the model to the proper GPU\n",
    "    model.to(device + ':' + str(rank)) # string addition, should end up as 'cuda:0', 'cuda:1' etc.\n",
    "\n",
    "    # partition the data; each worker/GPU gets its chunk of the data to work on,\n",
    "    # based on its rank and the total number of workers (the world size)\n",
    "    dataset_chunk_size = len(tokenized_ds['train']) // world_size\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        tokenized_ds['train'].select(range(rank * dataset_chunk_size, (rank + 1) * dataset_chunk_size)),\n",
    "        batch_size=16,\n",
    "        shuffle=False) # don't shuffle\n",
    "    \n",
    "    epochs = 1\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # unfortunately, because this now runs in a separate process, tqdm cannot display a progress bar to\n",
    "        # the main process; to make this work, extra work is needed to share the state with the main process\n",
    "        # using something like pipes or shared memory; we'll skip this for now\n",
    "        for batch in tqdm_notebook(dl, total=len(dl)):\n",
    "            # retrieve one batch of data from the dataloader\n",
    "            inputs = batch['input_ids']\n",
    "    \n",
    "            # move the inputs to GPU\n",
    "            inputs = inputs.to(device + ':' + str(rank))\n",
    "            \n",
    "            labels = inputs\n",
    "    \n",
    "            # before anything else, make sure we have no gradients yet calculated/saved,\n",
    "            # for any of the model parameters\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # calculate the output of the model (we need the \"logits\" of the model, which\n",
    "            # is what the output of the final linear layer is called)\n",
    "            output = model(inputs).logits\n",
    "            \n",
    "            # we are doing next-token prediction, so we shift label scores and outputs by 1\n",
    "            labels = labels[:, 1:].contiguous()\n",
    "            shifted_output = output[:, :-1, :].contiguous()\n",
    "    \n",
    "            # calculate the loss (error) of the model with respect to the labels\n",
    "            loss = loss_fn(shifted_output.view(-1, shifted_output.size(-1)), labels.view(-1))\n",
    "    \n",
    "            # save the loss value\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "            # this is where the magic happens; PyTorch now calculates the gradients AUTOMATICALLY for us,\n",
    "            # and the optimizer updates the parameters with these gradients (only AFTER synchronizing them\n",
    "            # with the rest of the workers)\n",
    "            loss.backward()\n",
    "    \n",
    "            # here's the extra lines that synchronize the gradients across multiple workers, after\n",
    "            # each worker calculated them in the backward pass\n",
    "            # notice that this is the ONLY synchronization point of the workers; everything\n",
    "            # else, after the initial setup, is done independently\n",
    "            for param in model.parameters():\n",
    "                dist.all_reduce(param.grad.data, op=dist.ReduceOp.SUM)\n",
    "                param.grad.data /= world_size\n",
    "    \n",
    "            # only after averaging the gradients, we can update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "    # save the model at the end; as all ranks hold the same model, we only need to save it from rank 0\n",
    "    if rank == 0:\n",
    "        model.save_pretrained('lab5_pretrained_model')\n",
    "\n",
    "    # let's also save the losses; only for first rank, because the rest should be the same\n",
    "    if rank == 0:\n",
    "        torch.save(losses, 'losses.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b8f6f-609b-44a1-a514-f19a9a5771a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b42a2b-33cf-45dc-8d2c-2aea83be9a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ed69380-f489-4e20-be64-fa91f106bb9a",
   "metadata": {},
   "source": [
    "## 3. Setting up multiple processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0c2ca-79e2-4060-a649-ed788a7ffd89",
   "metadata": {},
   "source": [
    "Finally, here comes the fun part! We need to set up multiple processes, one for each data parallel worker (or a so-called *model replica*). These processes need to know about each other. One of them is the main node, which coordinates the communication, while other nodes (in our case only 1 other) are workers, which connect to the main node to initiate distributed training.\n",
    "\n",
    "In order to exchange the gradients, we'll simply use All-Reduce operations (see [Pytorch's torch.distributed package](https://pytorch.org/docs/stable/distributed.html#torch.distributed.all_reduce))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc9708-d4c3-4926-9d37-b30af1138107",
   "metadata": {},
   "source": [
    "First of all, we need a way to initialize each process. This is the step which tells each GPU who to connect to, since we now have a group of processes to coordinate. For this, we'll simply write an `init_process` function, which receives the **rank** (i.e. GPU number inside the group of processes), the **world size** (the actual number of processes in the group), and the function to execute, after connecting to the main GPU (which will just be our training loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f41a259-443d-4bd2-94af-79d266aaf000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_process(rank, world_size, loop_fn):\n",
    "    # initialize distributed environment, by telling each worker\n",
    "    # where the master process can be found; since we know that\n",
    "    # our GPUs are all connected to the same PC, we'll just give it\n",
    "    # the localhost address, and a random port of our choosing\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "\n",
    "    # we'll use the NCCL backend (which is for Nvidia GPUs); if instead\n",
    "    # you want to run this on CPU, using MPI, you can switch to 'gloo' as\n",
    "    # backend\n",
    "    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "\n",
    "    # finally, launch the training loop\n",
    "    loop_fn(rank, world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad1bfe-6a9a-4027-a574-147e3d215cb3",
   "metadata": {},
   "source": [
    "Now, we need to actually start multiple processes. We'll just use the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) utility in python, using the _\"spawn\"_ method (which is simply using a syscall of `posix_spawn`, or `fork` + `exec` where that's not available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5059e85d-bb6b-45f8-a894-452a22c7f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the number of GPUs here; run 'nvidia-smi' on fep to see how many you have available\n",
    "world_size = 2\n",
    "    \n",
    "processes = []\n",
    "#mp.set_start_method(\"spawn\")\n",
    "\n",
    "# each GPU in a \"world\" (i.e. group of processes) is assigned a rank; we start each process\n",
    "# separately and tell it to connect to the main GPU (with rank 0) through the \"init_process\"\n",
    "# function above\n",
    "for rank in range(world_size):\n",
    "    p = mp.Process(target=init_process, args=(rank, world_size, training_loop_fn))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "# finally, wait for all to finish\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e30ae-38a2-4460-b2a1-975ae6614d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d2a46d-3c7b-4079-8176-1fbd75f278c2",
   "metadata": {},
   "source": [
    "## 4. Wrapping up (inference and loss visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f5ec95-43e2-49bb-8b48-fcfcf4f3336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1474945/3841630559.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  losses = torch.load('losses.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f053e8dff50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0SUlEQVR4nO3de3RU5aH38d/M5B6TSQIkM0iAgFGMETXWYLy9VaKEYqSnnvOqBZf1tFoRrbfTWs4qRpa2qO3bY21ttPYctaVodbWK9GAsBYGiAZSAGKMIGAQlASHkwiUJyez3jzgxQybJJJnZM5n9/ayVtcyeZ/Z+ZrbM/PJcbYZhGAIAADCJPdwVAAAA1kL4AAAApiJ8AAAAUxE+AACAqQgfAADAVIQPAABgKsIHAAAwFeEDAACYKibcFTiZx+PRvn37lJKSIpvNFu7qAACAABiGoZaWFo0dO1Z2e/9tGxEXPvbt26fs7OxwVwMAAAzB3r17NW7cuH7LRFz4SElJkdRV+dTU1DDXBgAABKK5uVnZ2dnd3+P9ibjw4e1qSU1NJXwAADDCBDJkggGnAADAVIQPAABgKsIHAAAwFeEDAACYivABAABMRfgAAACmInwAAABTET4AAICpIm6RsVDp9BjaVNugAy2tykxJUGFOhhx29o4BAMBslggfFdV1WrS8RnVNrd3H3M4ElZXmqSTfHcaaAQBgPVHf7VJRXad5S6p8gock1Te1at6SKlVU14WpZgAAWFNUh49Oj6FFy2tk+HnMe2zR8hp1evyVAAAAoRDV4WNTbUOvFo+eDEl1Ta3aVNtgXqUAALC4qA4fB1r6Dh5DKQcAAIYvqsNHZkpCUMsBAIDhi+rwUZiTIbczQX1NqLWpa9ZLYU6GmdUCAMDSojp8OOw2lZXmSVKvAOL9vaw0j/U+AAAwUVSHD0kqyXerfG6BXE7frhWXM0HlcwtY5wMAAJNZYpGxkny3rsxzscIpAAARwBLhQ+rqgimaPCrc1QAAwPKivtsFAABEFsIHAAAwFeEDAACYivABAABMRfgAAACmInwAAABTET4AAICpCB8AAMBUhA8AAGAqwgcAADAV4QMAAJiK8AEAAExF+AAAAKYifAAAAFMRPgAAgKkIHwAAwFSEDwAAYCrCBwAAMBXhAwAAmIrwAQAATEX4AAAApiJ8AAAAUxE+AACAqQgfAADAVIQPAABgqkGHj3Xr1qm0tFRjx46VzWbTq6++6vO4YRh64IEH5Ha7lZiYqOLiYu3YsSNY9QUAACPcoMPH0aNHdc455+jJJ5/0+/hjjz2mJ554Qk899ZQ2btyo5ORkzZgxQ62trcOuLAAAGPliBvuEmTNnaubMmX4fMwxDjz/+uH7yk59o9uzZkqQ//OEPysrK0quvvqrrr79+eLUFAAAjXlDHfNTW1qq+vl7FxcXdx5xOp6ZNm6bKykq/z2lra1Nzc7PPTyh0egxV7jqkZVs/V+WuQ+r0GCG5DgAA6N+gWz76U19fL0nKysryOZ6VldX92MkWL16sRYsWBbMavVRU12nR8hrVNX3V9eN2JqisNE8l+e6QXhsAAPgK+2yXBQsWqKmpqftn7969QT1/RXWd5i2p8gkeklTf1Kp5S6pUUV0X1OsBAID+BTV8uFwuSdL+/ft9ju/fv7/7sZPFx8crNTXV5ydYOj2GFi2vkb8OFu+xRctr6IIBAMBEQQ0fOTk5crlcWrVqVfex5uZmbdy4UUVFRcG8VEA21Tb0avHoyZBU19SqTbUN5lUKAACLG/SYjyNHjmjnzp3dv9fW1mrr1q3KyMjQ+PHjdffdd+vhhx9Wbm6ucnJytHDhQo0dO1bf/OY3g1nvgBxoCWx6b6DlAADA8A06fLz77ru6/PLLu3+/9957JUk33XSTnnvuOf3oRz/S0aNHdeutt6qxsVGXXHKJKioqlJCQELxaBygzJbBrBloOAAAMn80wjIga8NDc3Cyn06mmpqZhj//o9Bi65NHVqm9q9TvuwybJ5UzQ+vuvkMNuG9a1AACwssF8f4d9tksoOew2lZXmSeoKGj15fy8rzSN4AABgoqgOH5JUku9W+dwCuZy+XSsuZ4LK5xawzgcAACYL6iJjkaok360r81zaVNugAy2tykxJUGFOBi0eAACEgSXCh9TVBVM0eVS4qwEAgOVFfbcLAACILIQPAABgKsIHAAAwFeEDAACYivABAABMRfgAAACmInwAAABTET4AAICpCB8AAMBUhA8AAGAqwgcAADAV4QMAAJiK8AEAAExF+AAAAKYifAAAAFMRPgAAgKkIHwAAwFSEDwAAYKqYcFfALJ0eQ5tqG3SgpVWZKQkqzMmQw24Ld7UAALAcS4SPiuo6LVpeo7qm1u5jbmeCykrzVJLvDmPNAACwnqjvdqmortO8JVU+wUOS6ptaNW9JlSqq68JUMwAArCmqw0enx9Ci5TUy/DzmPbZoeY06Pf5KAACAUIjq8LGptqFXi0dPhqS6plZtqm0wr1IAAFhcVIePAy19B4+hlAMAAMMX1eEjMyUhqOUAAMDwRXX4KMzJkNuZoL4m1NrUNeulMCfDzGoBAGBpUR0+HHabykrzJKlXAPH+Xlaax3ofAACYKKrDhySV5LtVPrdALqdv14rLmaDyuQWs8wEAgMksschYSb5bV+a5WOEUAIAIYInwIXV1wRRNHhXuagAAYHlR3+0CAAAiC+EDAACYivABAABMZZkxH1LXXi8MOgUAILwsEz4qquu0aHmNz14vbmeCykrzmG4LAICJLNHtUlFdp3lLqnptMlff1Kp5S6pUUV0XppoBAGA9UR8+Oj2GFi2vkeHnMe+xRctr1OnxVwIAAARb1IePTbUNvVo8ejIk1TW1alNtg3mVAgDAwqI+fBxo6Tt4DKUcAAAYnqgPH5kpCQMXGkQ5AAAwPFEfPgpzMuR2JvTa1dbLpq5ZL4U5GWZWCwAAy4r68OGw21RWmidJvQKI9/ey0jzW+wAAwCRRHz6krl1ty+cWyOX07VpxORNUPreAdT4AADCRZRYZK8l368o8FyucAgAQZpYJH1JXF0zR5FHhrgYAAJZmiW4XAAAQOQgfAADAVIQPAABgKkuN+ej0GAw4BQAgzCwTPiqq67RoeY3PPi9uZ4LKSvOYagsAgIks0e1SUV2neUuqem0wV9/UqnlLqlRRXRemmgEAYD1RHz46PYYWLa+R4ecx77FFy2vU6fFXAgAABFvQw0dnZ6cWLlyonJwcJSYmavLkyXrooYdkGOH5ct9U29CrxaMnQ1JdU6s21TaYVykAACws6GM+Hn30UZWXl+v555/XWWedpXfffVc333yznE6nfvCDHwT7cgM60NJ38BhKOQAAMDxBDx9vv/22Zs+erVmzZkmSJk6cqBdeeEGbNm0K9qUCkpmSMHChQZQDAADDE/Rul4suukirVq3Sxx9/LEl67733tH79es2cOTPYlwpIYU6G3M6EXjvaetnUNeulMCfDzGoBAGBZQW/5+PGPf6zm5mZNmTJFDodDnZ2d+ulPf6o5c+b4Ld/W1qa2trbu35ubm4NaH4fdprLSPM1bUiWb5DPw1BtIykrzWO8DAACTBL3l46WXXtKf/vQnLV26VFVVVXr++ef1i1/8Qs8//7zf8osXL5bT6ez+yc7ODnaVVJLvVvncArmcvl0rLmeCyucWsM4HAAAmshlBnoaSnZ2tH//4x5o/f373sYcfflhLlizRRx991Ku8v5aP7OxsNTU1KTU1NZhVY4VTAABCpLm5WU6nM6Dv76B3uxw7dkx2u2+DisPhkMfj8Vs+Pj5e8fHxwa6GXw67TUWTR5lyLQAA4F/Qw0dpaal++tOfavz48TrrrLO0ZcsW/fKXv9S///u/B/tSAABgBAp6t0tLS4sWLlyoV155RQcOHNDYsWN1ww036IEHHlBcXNyAzx9Msw0AAIgMg/n+Dnr4GC7CBwAAI89gvr+jfm8XAAAQWQgfAADAVEEfcBrJmGoLAED4WSZ8VFTXadHyGp8dbt3OBJWV5rHIGAAAJrJEt0tFdZ3mLanyCR6SVN/UqnlLqlRRXRemmgEAYD1RHz46PYYWLa+Rvyk93mOLlteo0xNRk34AAIhaUR8+NtU29Grx6MmQVNfUqk21DeZVCgAAC4v68HGgpe/gMZRyAABgeKI+fGSmJAxcaBDlAADA8ER9+CjMyZDbmaC+JtTa1DXrpTAnw8xqAQBgWVEfPhx2m8pK8ySpVwDx/l5Wmsd6HwAAmCTqw4ckleS7VT63QC6nb9eKy5mg8rkFrPMBAICJLLPIWEm+W1fmuVjhFACAMLNM+JC6umCKJo8KdzUAALA0S4UP9nYBACD8LBM+2NsFAIDIYIkBp+ztAgBA5Ij68MHeLgAARJaoDx/s7QIAQGSJ+vDB3i4AAESWqA8f7O0CAEBkifrwwd4uAABElqgPH+ztAgBAZIn68CGxtwsAAJHEMouMsbcLAACRwRItHwAAIHJYpuWD5dUBAIgMlmj5YHl1AAAiR9SHD5ZXBwAgskR9+GB5dQAAIkvUhw+WVwcAILJEffhgeXUAACJL1IcPllcHACCyRH34YHl1AAAiS9SHD4nl1QEAiCSWWWSM5dUBAIgMlgkfUlcXTNHkUeGuBgAAlmap8CF1LTpG6wcAAOFjqfDB/i4AAISfJQacSuzvAgBApLBE+GB/FwAAIoclwgf7uwAAEDksET7Y3wUAgMhhifDB/i4AAEQOS4QP9ncBACByWCJ8sL8LAACRwxLhQ2J/FwAAIoWlFhkryXfriilZ+mPlbn3acEwTMpJ0Y9FExcVYJoMBABB2lgof/lY4/f36WlY4BQDARJb5k58VTgEAiAyWCB+scAoAQOSwRPhghVMAACKHJcIHK5wCABA5LBE+WOEUAIDIYYnwUZiTobSk2H7LpCXFssIpAAAmsET4CARrmwIAYA5LhI9NtQ1qPHai3zKHj51gwCkAACYISfj4/PPPNXfuXI0aNUqJiYk6++yz9e6774biUgFhwCkAAJEj6CucHj58WBdffLEuv/xyvf766xozZox27Nih9PT0YF8qYAw4BQAgcgQ9fDz66KPKzs7Ws88+230sJycn2JcZlMKcDLmdCapvavW70JhNXRvMMeAUAIDQC3q3y2uvvaavfe1r+rd/+zdlZmbqvPPO0zPPPNNn+ba2NjU3N/v8BJvDblNZaZ6k3gNLvb+XlebJYWfYKQAAoRb08PHJJ5+ovLxcubm5euONNzRv3jz94Ac/0PPPP++3/OLFi+V0Ort/srOzg10lSV072pbPLVBWarzP8azUeJXPLWBjOQAATBL08OHxeFRQUKCf/exnOu+883Trrbfqlltu0VNPPeW3/IIFC9TU1NT9s3fv3mBX6SR9tX0AAAAzBD18uN1u5eXl+Rw788wztWfPHr/l4+PjlZqa6vMTCt5dbeubfWe07G9mV1sAAMwU9PBx8cUXa/v27T7HPv74Y02YMCHYlwoYu9oCABA5gh4+7rnnHm3YsEE/+9nPtHPnTi1dulS/+93vNH/+/GBfKmDsagsAQOQIevi44IIL9Morr+iFF15Qfn6+HnroIT3++OOaM2dOsC8VMBYZAwAgcgR9nQ9Juvrqq3X11VeH4tRDMjo5fuBCgygHAACGzhJ7uwQ8oYWJLwAAhJwlwsfBI21BLQcAAIbOEuEj0D1bdh88FuKaAAAAS4SPwpwMuVIHHs/x7Nu1TLcFACDELBE+HHabrrtg4GXbG4+d0IZdh0yoEQAA1mWJ8CEp4BaNyk8OhrgmAABYm2XCR0eA4SPQcgAAYGgsEz6OtHYEVK5mX3OIawIAgLVZJnwE2p6xsbaBQacAAISQZcKHPcAFxNo6PNrwCYNOAQAIFcuEj/Oy0wMuW8mMFwAAQsYy4cOdlhhwWY/hCWFNAACwNsuEj8KcDJ0SH9jL3d/MMusAAISKZcKHw27TvxYMvNCYJP1tWx2DTgEACBHLhA9Jys5ICqhcW4dHb+9ksTEAAELBUuEjIzku4LJ/2bw3hDUBAMC6LBU+XM7AB51+1tgawpoAAGBdlgofhTkZio8JbMGPxmPtIa4NAADWZKnw4bDb9P1LJwVUdtfBo2rvYMotAADBZqnwIUl3XXmGHAE0fhiG9MfK3SGvDwAAVmO58OGw2zTFnRJQ2U8bjoW4NgAAWI/lwkenx9Cnh44GVDY7PfABqgAAIDCWCx+baht0pC2wsRxTXKkhrg0AANZjufBxoCXwKbQNzHgBACDoLBc+MlMSAi5b+0Vg3TMAACBwlgsfhTkZSk+MCajsU2t3sccLAABBZrnw4bDbdOHk0QGVbe3w6NerdoS4RgAAWIvlwockTR6THHDZ36//hNYPAACCyJLho2hSYC0fknSkrVObahtCWBsAAKzFkuHjwsmjBvXCBzNDBgAA9M+S4cNhtyl/XOBreAxmhgwAAOifJcOHJJVOPTWgcqkJMSrMyQhxbQAAsA7Lho+bLpooWwAbzP3b17LlsAdQEAAABMSy4SMuxq7vXTJxwHIr3q9jtgsAAEFk2fAhSVdMcQ1Ypq6pldkuAAAEkaXDR33T8YDK/f2DuhDXBAAA67B0+Gg4GtjGcX+p+pyuFwAAgsTS4SM9KS6gcs2tHXS9AAAQJJYOH4ePBdbyIQXeRQMAAPpn6fCRkRxYy4cUeBcNAADon6XDh8uZGHDZtAC7aAAAQP8sHT4KczJ0SrwjoLJv7zoY4toAAGANlg4fDrtNl5wW2A63b3xQz4wXAACCwNLhQ5JOyzwloHJH2jqZ8QIAQBBYPnwUTQqs5UNixgsAAMFg+fBx4eRRio8JbOO4g0eY8QIAwHBZPnw47Dad6U4JqGzjccIHAADDZfnw0ekxtGP/0YDKfvLFkRDXBgCA6Gf58LGptkFH2zsDKvvPHYeY8QIAwDBZPnwcaGkNuOyRtg5t2HUohLUBACD6WT58ZKYkDKp85ScsNgYAwHBYPnwU5mQoOcBVTiVp5wHGfQAAMByWDx8Ou03/JzfwtT7e3sW4DwAAhsPy4UOS5kybGHDZ5tYOVjoFAGAYCB/qWmgsKS7wt6K+OfBBqgAAwBfhQ11dL9+7JCfg8g1H2kJYGwAAohvh40uDGcbx2eFjoasIAABRLuTh45FHHpHNZtPdd98d6ksNU2D7u0jSkg17GHQKAMAQhTR8vPPOO3r66ac1derUUF4mKIomjwq47AmPoV+t/DiEtQEAIHqFLHwcOXJEc+bM0TPPPKP09PRQXSZoLpwU+O62kvTM+k9o/QAAYAhCFj7mz5+vWbNmqbi4uN9ybW1tam5u9vkJB4fdpulTMgMuf/yEhym3AAAMQUjCx4svvqiqqiotXrx4wLKLFy+W0+ns/snOzg5FlQIymPU+pMHtCwMAALoEPXzs3btXd911l/70pz8pIWHgfVMWLFigpqam7p+9e/cGu0oBu3DyKCXFBv6WDHZfGAAAEILwsXnzZh04cEAFBQWKiYlRTEyM1q5dqyeeeEIxMTHq7PTdvj4+Pl6pqak+P+HisNt03QWBt7zQ8gEAwODFBPuE06dP1/vvv+9z7Oabb9aUKVN0//33y+EIfBO3cBiXnhRw2Xv+vFVXTx0rhz3wgaoAAFhd0MNHSkqK8vPzfY4lJydr1KhRvY5HoozkuIDLegzp8ZXbdd+MKSGsEQAA0YUVTk/iciYOqvzT62qZcgsAwCAEveXDnzVr1phxmaAozMlQcpxdR9s9AZVv7+yacjuYRcoAALAyWj5O4rDbdMHEjEE95+8f1IWoNgAARB/Chx+X5o4ZVPln3/5Uv/rHx3S/AAAQAMKHHzcWTRzENnNd/usfO/S1h1dqxbZ9IakTAADRgvDhR1yMXVdPdQ36eYePndDtS7do8YqaENQKAIDoQPjoQ3He4MOH19PrarViG+NAAADwh/DRh+Eunb5wWTVjQAAA8IPw0YfCnAwlxw99NdZDR9vZ9RYAAD8IH31w2G265ZKcYZ2DvV8AAOiN8NGPO6efLscwtm3ZffBY8CoDAECUIHz0w2G3af7lk4f8/Gff+oRxHwAAnITwMYC7is8Y8pvUeLxDv161I6j1AQBgpCN8DMBht+nO6acN+fmPr9qhimqm3QIA4EX4CEBhzvA2jVu0vIbuFwAAvkT4CMDBI23Den5dUyvTbgEA+BLhIwDDXXBMkuqbjgehJgAAjHyEjwAU5mTIlRo/rHMMt/UEAIBoQfgIgMNu04PXnDWsc/zi7x/3Gnja6TFUueuQlm39XJW7DjEuBABgCTHhrsBIUZLv1tdPH601Hx8c0vPbOjyat6RK5XMLVJLvVkV1nRYtr1Fd01eroLqdCSorzVNJvjtY1QYAIOLQ8jEIl+aOGdbzDUn3/vk93ffSVs1bUuUTPCSpvqlV85ZUMTUXABDVCB+DcGPRRNmHsdy6JB070am/VH0ufx0s3mNMzQUARDPCxyDExdh1y6XD22xuIIaYmgsAiG6Ej0Fa8I08zTo7K+TXYUdcAEC0InwMwRM3nK+0xNiQXiMYa4sAABCJCB9D4LDb9Mi1Z4fs/G5nggpzMkJ2fgAAwonwMUQl+W49NbdAzhC0gFxzjluO4Y5sBQAgQhE+hqEk363fzikI+nlffGcvs10AAFGL8DFMF0zMULDbKJqOd+jXq3YE+awAAEQGwscwbf70sN81O4br8VU7WGwMABCVCB/DFMopsfe9/J7aOzwhOz8AAOFA+BimUE6JPdrWqQt/tooWEABAVCF8DFNhTobczoSgj/vwajjWrtvY7wUAEEUIH8PksNtUVponSSELIJJ0x5+q9JNX3tfx9s4QXgUAgNAjfARBSb5b5XML5HKGrgumw5CWbNyjMx+o0LXlbzEVFwAwYtkMw4iob7Hm5mY5nU41NTUpNTU13NUZlE6PoU21DVpZU6//eWt3SK8VY5OuOitLk8akqGjyKF04aRQLkwEAwmYw39+EjxCpqK7Tj//6vhqPnTDlemlJsXrkW2erJN9tyvUAAOiJ8BEhOj2Gnli1Q78yccGwy3JH65vnnip3WqIKczJoDQEAmILwEWFWbKvT7UurTL+u25mgstI8WkMAACE3mO9vBpya4BtTuzahS0uMMfW6dU2tum1JlVZs22fqdQEA6A/hwyQl+W5tXniVnr/pAtOvPX/pFq3YVqdOj6HKXYe0bOvnqtx1iBkzAICwMPdPcYtz2G36P2dm6vuX5ejpdbWmXdeQdPvSKiXE2NXaY7l2umUAAOFAy0cYLPhGnr5/WY7p1209aZ8Yb7fMbX98V2/tPEhLCADAFAw4DaPj7Z06u6xCHRFyB5LiHPr+ZZN0xxW5zJIBAAwKA05HiMQ4h34zpyDc1eh2rL1T//WPHZq66A09tPwDxoUAAEKClo8IUFFdp3tf2qpj7Z6BC5vMlRqv6y7I/jKE2FhNFQDgF+t8jECdHkPPrN2lR97YHu6qDMjfaqrepeUPtLQqMyVB509I1+ZPD3f/zoJnABDdCB8jVKfH0PkPrzRtSfbh+u7FE3XFlCy9s7tBz729W43Hv6q33Sb17LGJlJk1J4ckQhEABAfhYwSrqK7TbUvMXw3VLN+9eKKK81xh+dKvqK7TouU1qmtq7T4WKaEIAEY6wscIV1Fdpwdf+0D1zW3hrkrIuJ0JWjjrTKUnxw+6FWIorRcV1XWat6RKJ//P7n1W+dwCAggADAPhIwp4v2Df2vmFfvPmrnBXxxSBtEIE2nrRM6CMTo7XfS+/p/rmVn+nlE2Sy5mg9fdfQRcMAAwR4SOKdHoMXfLoatU3tfb6qz1a9dU1E2jrhb+AEogXbrlQRZNHDa/yAGBRrPMRRRx2m8pK8yR99SUb7f77rd264ZkNuuTR1aqorpPUFcIefK3GbwDzHlu0vEYrtnUFlMEGD0k60DL45wAABo/wMQKU5LtVPrdALmdCuKtiKu/y7//v7x9p1q/W9dltInUFkLqmVv1kWfWQW4gyU6z1/gJAuNDtMoL0HMew++AxvbBpT79fyAgMYz4AYPgG8/3NrrYjiMNu8xmTcMcVp3WHkYr36/T6B/vDWLuRyRs1ykrzCB4AYBLCxwjWM4zMPvdUrdhWp/v/uk0trR1hrtnI4eoxUyYUC5CxqBkA9Ea3S5Rp7/DowsWr1HC0PdxViXgpCQ5967xTNT4jWZ81Hteyrft83reM5Fg9PDtf35g6VtLggwSLmgGwkrBOtV28eLH++te/6qOPPlJiYqIuuugiPfroozrjjDMCej7hY/j6mpKKoTk3O1VfPz1LL76z12eMTX9BIliLmtFyAmCkCGv4KCkp0fXXX68LLrhAHR0d+s///E9VV1erpqZGycnJAz6f8BEcQ13rAoHzFyQ6PYY27Dqk+UurfPa6OVlWSpzeXlAclJYTAgqASBBRi4x98cUXyszM1Nq1a3XZZZcNWJ7wETzeL6X6puN66H8/1OGj7bSGBJlNUlZqvP7f/z1Xqz7cr1dP6rrpz9VT3frNtwt6He/0GPr1qh16fNUOv9eT+l9Qja4dAOEQUeFj586dys3N1fvvv6/8/PwByxM+QsPbDSDJJ4DYvvw9Mdam4yeIJmYbmxovd3qistOTdG3BOLW0dmjBK9vUdLz/QcNZKXG6oXCC34DidU9xru64IjciWkFonbEO7rV1RUz48Hg8uuaaa9TY2Kj169f7LdPW1qa2tq82UGtublZ2djbhIwT6+yv5yjyXfvWPj/XE6p1hrCGCLSslXotmnxXWVhBaZ6yDe21tERM+5s2bp9dff13r16/XuHHj/JZ58MEHtWjRol7HCR+hMdBfJYtX1OjpdbVhrCFC4a7pp6kwZ5QOHmnze99P/v/i/Anp2vzpYdU3HVfD0XZlnBIvV+rgdx5eWVOv/3lrd5/l+trHx+pGYusBO0cjIsLHHXfcoWXLlmndunXKycnpsxwtH5FnxbY6/egv23SkjfVColVqQoyuysvSxbljtOdQ79Vy7TbJ4+eTwTv9eEa+u88vx6EMdnalxuvBa4LbQmP2F3iwrjcSWw+8G2D2dc9ZRdgawho+DMPQnXfeqVdeeUVr1qxRbm7uoJ7PmI/I4J21UfnJQUk2TcvJkN1u6/7L+eCRNj2wrFqHj/U9owPRK9Zh04nOrz463M4ELZx1pnYcOKr/+sfHQz7v3dNP053TT5ek7i/y0cnxkk3d/+95W2X6+pL3Dtj9/fpPdKSt06eOofoCD1ZgGKmtB5W7DumGZzYMWI6do6NbWMPH7bffrqVLl2rZsmU+a3s4nU4lJiYO+HzCx8jRczbNgZZWfVjXos8OH9e7nx4Od9UwgsU6bEqOi+lzqrLNJvX81Oq5GFxFdZ3ufek9HWvv9P9cdX2BX5nnClqrSDDXdOmv9UDqCjShaD0YbqvNsq2f664Xtw5Y7lfXn6vZ5546jJqaYyR2e0WCsO7tUl5eLkn6+te/7nP82Wef1Xe+851gXw5hdPJeM1JgH6BAf050Gv2ukXLyn0sNR0/o9qVblL9mp6r3tfR7bkPSnUurFBvj8AkortQEPXhNnq6YkqU/Vu5W7aGjskk6Lztd7rTEPr98Oj2GFi2v8TuF3Xvsx395XykJsbpw0ig57LZerYpFk0fpwkmjtKm2YcB/N3VNrdpU26DCnIygfDl2egz9ZvVOPftWrc977m3JSk+O77eFyVuHgy1t/k7fy0jYOXokdnuNRCyvjqBjhVWMVCe3qnilJDj0rwXjVHymSx7D0MbaQ5JscibG6qcrPgzo3K7UeM0+d6z+/O5najypuzIpzqFLTxulN2oODHieK6aM0Yd1LUHp4vnxX9/vVZe+9LyGvy/ovt47aeSM+RjosyuSpq9HoogYcDpUhI/oUFFdpwdf+0D1zYH9RQRg+G6+aILGpScNODuporpOt3257s9g3XJpjn7/z9qA/7iI9PEqXoG22npbySL5tYQL4QMRwdukO5QBiKc6E/TFkTa1d0bU/57AiJKS4ND549N1ae4Y3Vg0UXExdtO7RjOSY/Uv556qK6Zk+Qwc7hmM/I2xkOS3e6qvVoee3VkeQ0pPitPolK4QNtAgZSnwQbPSV2OHvLthD6ae0YzwgYjSVx/qNee49dp7dX02Hw8nvADo7cKcdJ0/MUNPvrkrpNexSfr6GWP03mdNfW43kJLgUEF2mjySqj5t1NEeY3DSkmLV3uHpNXA41i5NHnOKskclqXDiKN10UVegGqgL6eSp4yfvWC0FPmjW+/pczgQtnJWn/3y193XTkmL1yLfODnrryHAGwpoxiJbwgYjT1//4gfyDYJM8AH0Zc0qsvjgytCn/378sRwu+kSdJemvnQc35/cZgVk0lZ2XpxqKJumBiht6pbejVKpN5ylfTyE+eUn5yy5C/gcFpibG6+eKJA45D8dcNHoq1dQgfiDo9Q8ro5Hh5DEN/qNytlR8OPEAPAPry228XyG6XypZ9oP0BztoxQ3pSjG68cIK27z+i1R8d8FlX52RJcQ59/7JJuvWyyVqyYbfe2X1YyXEOfevL/aJuX9r3+J6ngjgWh/ABSxhMHy0A+HPygnlWk5YUq80/uTIoXTCD+f62D/tqQJgU5mTI7UyQ9YZ1AQgWKwcPSWo8dkIbdh0y/bqED4xYDrtNZaVd/bUEEAAYml/8/SPTr0n4wIhWku9W+dwCuZy+KyemJcVK6juUpCfF6p7iwPYdujR3lGKDOCp82sR0ZacFvtJjWmKs/rUg8pekBjAybdnbpBXb6ky9ZtCXVwfMVpLv9rtXx8qa+l6zZHqODpekF9/Zq/qmVr8LJtkkOZNitX7HoUGv1nr39Fz9YcOnPtMMe04j/u9/fqKH/nfglTFvvHC8HrwmX5L01q5DzPgBEBI/WVatGfku09YnIXwgKvjbZ6avUNLzH1dZaZ7mLamSTfIJGD1/H0zw8M7/v3N6ru6cntvntTOS4wI6X8H49O7neOtq7R5qAKHQcLRdm2obTNt1mG4XRDVvKJl97qkqmtx71cG+um1czgTdU5wb8L4X0lddPGWleXLYbf1e2+UceIfnk8t11zU1PuA65blPCbgsAGurbzpu2rVo+YDl9dVC8rdt+wZ1HtcgNvfyztQZaPt07zLTJ9d1oJVf05NitfjLFRaHs0hbnMPms8S9MzFG37loojo8RshXyQRgrr5Wow0Fwgcg/902gW7/fcflp+ni00YParli70ydvrpRbPqqBcXfc+8qztUZrlP6HdPifa6/cHX4aLvfZaG9vMtPz8h3++06qtx1KKDwkRBjl8MuHW33BPS+AAifjFMCb1UdLsIH0Adv60R/A1JdzgTdc+XpQxqk5e1G8bfvTSAtKIGMafHyF65m5Lv63Iir53n89QEP9N5IXQFmw4JiOey2iNujp7/t3wGrcqUGPgtvuFjhFOhHRXWd5n259fjJA1Kl4GwTbsaGT6Ew2PdmsN0/+WNT5UyM1Za9jb02GBustMQYPTnn/O59Mw4fbdf8pQzeBbzczgStv/+KYX32sLw6EER97cob6PiOaDbY96bTY+i5t2oDmmb8wi0XqmjyqO6QM5wPKn/7V/QXhk7eBXUwhvNcIFx+++0CfWPq8D7PCB9AkI3U1gkzDPa96fQYuuTR1QN2Z/X8K8xfUMhIjtW1BeP0+3/WSvI/JbrnwNv+6l7fdFwNR9uVcUpXt5O3ZaSv8/blnuJczfv6adr86eHu9+PgkTaVvfZBrzVfFs46U+nJ8T6bJW6sPaSP9x/RP3d8oeMnvhonk5USp29Pm6CJo5O1++AxvbBpj+qb+29BOnn6ONAfb9gfDsIHgIg2lO6svkKOv2AS6FbjA9Wx13mTYtXe4enVDZSWGKNHrp06YMgZTEDrr7z38ZU19Xp16z6fYON97bmZKSHrWoq1d923DsYRR41fXX+uZp87vJWUCR8AIl4wu7NC1TLl77ySugfqSl0DeS+c1HsNGbP099qHMs06Icau1n5SRc+BxHe9uEX/u62OFpYoQMsH4QOwDLqzQq9n19JD//uhDh9t77e7a+GsPL8tJn21SrV3ePTHyt1at+OgNtUe8uku6svCWWdqdEq8/rL5M63bcXCoL03JcQ4dHeZgZLM5E2PUdLwjqOeMddh8dufNSonTBTmjtPqjAwMO1vbXzTlUhA8AQC+BdncNtVWqvcOjCxev6nexqp6zKto7PJqy8PUBB+hmJMWp4VjvfZIkjZgtB9ISY/XItWcHtEjgPcW5Gp+RpIaj7UpNjNW2zxq1p+G4qvYcVkvrV8HF+z70NeW+02PoN6t36ul1u/yGkGDO2pMIHwCAPgQaLIbaKjXY8TyLV9To6XW1fZ7v+5fl6EclZwa1a6kvA3U5DcefvjtNF+eO7v69orpOD75W4zNweKCAN9R74g0hz75Vq8bjXy0sGOxZe4QPAECfQt3dNdiWk8UravTMP2t9WkDsNumWS3O04Bt5A16v5+sJdDbQyX777fNkt9t025fBqS9DmUWUlhSrzT+5std7bHa3Y6ivR/gAAITVYL/ovGNHPm04pgkZSbqxaKLiYoa292mnx9CGXYc0f2mVz1/6/pwcivprkZA0pFaWe4pP113FuYN8FSMP4QMAYHl9dQF53VOc63c6dn/Bqedjo5Pjdd/L72l/c9/bDPTV6hGNCB8AACj0KxQPFHD8ra4brQgfAAB8KdLGuEQrwgcAACZizZrBfX/HmFQnAACilsNuG/YKoVYytKHEAAAAQ0T4AAAApiJ8AAAAUxE+AACAqQgfAADAVIQPAABgKsIHAAAwFeEDAACYivABAABMFXErnHpXe29ubg5zTQAAQKC839uB7NoSceGjpaVFkpSdnR3mmgAAgMFqaWmR0+nst0zEbSzn8Xi0b98+paSkyGYL7qY8zc3Nys7O1t69e9m0LkJxjyIf92hk4D5Fvmi7R4ZhqKWlRWPHjpXd3v+ojohr+bDb7Ro3blxIr5GamhoVNzqacY8iH/doZOA+Rb5oukcDtXh4MeAUAACYivABAABMZanwER8fr7KyMsXHx4e7KugD9yjycY9GBu5T5LPyPYq4AacAACC6WarlAwAAhB/hAwAAmIrwAQAATEX4AAAAprJM+HjyySc1ceJEJSQkaNq0adq0aVO4q2QZDz74oGw2m8/PlClTuh9vbW3V/PnzNWrUKJ1yyim69tprtX//fp9z7NmzR7NmzVJSUpIyMzP1wx/+UB0dHWa/lKixbt06lZaWauzYsbLZbHr11Vd9HjcMQw888IDcbrcSExNVXFysHTt2+JRpaGjQnDlzlJqaqrS0NH33u9/VkSNHfMps27ZNl156qRISEpSdna3HHnss1C8tqgx0n77zne/0+rdVUlLiU4b7FFqLFy/WBRdcoJSUFGVmZuqb3/ymtm/f7lMmWJ9xa9asUUFBgeLj43XaaafpueeeC/XLCxlLhI8///nPuvfee1VWVqaqqiqdc845mjFjhg4cOBDuqlnGWWedpbq6uu6f9evXdz92zz33aPny5Xr55Ze1du1a7du3T9/61re6H+/s7NSsWbPU3t6ut99+W88//7yee+45PfDAA+F4KVHh6NGjOuecc/Tkk0/6ffyxxx7TE088oaeeekobN25UcnKyZsyYodbW1u4yc+bM0QcffKCVK1fqb3/7m9atW6dbb721+/Hm5mZdddVVmjBhgjZv3qyf//znevDBB/W73/0u5K8vWgx0nySppKTE59/WCy+84PM49ym01q5dq/nz52vDhg1auXKlTpw4oauuukpHjx7tLhOMz7ja2lrNmjVLl19+ubZu3aq7775b3/ve9/TGG2+Y+nqDxrCAwsJCY/78+d2/d3Z2GmPHjjUWL14cxlpZR1lZmXHOOef4fayxsdGIjY01Xn755e5jH374oSHJqKysNAzDMFasWGHY7Xajvr6+u0x5ebmRmppqtLW1hbTuViDJeOWVV7p/93g8hsvlMn7+8593H2tsbDTi4+ONF154wTAMw6ipqTEkGe+88053mddff92w2WzG559/bhiGYfz2t7810tPTfe7R/fffb5xxxhkhfkXR6eT7ZBiGcdNNNxmzZ8/u8zncJ/MdOHDAkGSsXbvWMIzgfcb96Ec/Ms466yyfa1133XXGjBkzQv2SQiLqWz7a29u1efNmFRcXdx+z2+0qLi5WZWVlGGtmLTt27NDYsWM1adIkzZkzR3v27JEkbd68WSdOnPC5P1OmTNH48eO7709lZaXOPvtsZWVldZeZMWOGmpub9cEHH5j7QiygtrZW9fX1PvfE6XRq2rRpPvckLS1NX/va17rLFBcXy263a+PGjd1lLrvsMsXFxXWXmTFjhrZv367Dhw+b9Gqi35o1a5SZmakzzjhD8+bN06FDh7of4z6Zr6mpSZKUkZEhKXifcZWVlT7n8JYZqd9jUR8+Dh48qM7OTp+bKklZWVmqr68PU62sZdq0aXruuedUUVGh8vJy1dbW6tJLL1VLS4vq6+sVFxentLQ0n+f0vD/19fV+75/3MQSX9z3t799MfX29MjMzfR6PiYlRRkYG981EJSUl+sMf/qBVq1bp0Ucf1dq1azVz5kx1dnZK4j6ZzePx6O6779bFF1+s/Px8SQraZ1xfZZqbm3X8+PFQvJyQirhdbRF9Zs6c2f3fU6dO1bRp0zRhwgS99NJLSkxMDGPNgJHt+uuv7/7vs88+W1OnTtXkyZO1Zs0aTZ8+PYw1s6b58+erurraZ0wb/Iv6lo/Ro0fL4XD0Glm8f/9+uVyuMNXK2tLS0nT66adr586dcrlcam9vV2Njo0+ZnvfH5XL5vX/exxBc3ve0v38zLper14Dtjo4ONTQ0cN/CaNKkSRo9erR27twpiftkpjvuuEN/+9vf9Oabb2rcuHHdx4P1GddXmdTU1BH5R1zUh4+4uDidf/75WrVqVfcxj8ejVatWqaioKIw1s64jR45o165dcrvdOv/88xUbG+tzf7Zv3649e/Z035+ioiK9//77Ph+iK1euVGpqqvLy8kyvf7TLycmRy+XyuSfNzc3auHGjzz1pbGzU5s2bu8usXr1aHo9H06ZN6y6zbt06nThxorvMypUrdcYZZyg9Pd2kV2Mtn332mQ4dOiS32y2J+2QGwzB0xx136JVXXtHq1auVk5Pj83iwPuOKiop8zuEtM2K/x8I94tUML774ohEfH28899xzRk1NjXHrrbcaaWlpPiOLETr33XefsWbNGqO2ttZ46623jOLiYmP06NHGgQMHDMMwjNtuu80YP368sXr1auPdd981ioqKjKKiou7nd3R0GPn5+cZVV11lbN261aioqDDGjBljLFiwIFwvacRraWkxtmzZYmzZssWQZPzyl780tmzZYnz66aeGYRjGI488YqSlpRnLli0ztm3bZsyePdvIyckxjh8/3n2OkpIS47zzzjM2btxorF+/3sjNzTVuuOGG7scbGxuNrKws48YbbzSqq6uNF1980UhKSjKefvpp01/vSNXffWppaTH+4z/+w6isrDRqa2uNf/zjH0ZBQYGRm5trtLa2dp+D+xRa8+bNM5xOp7FmzRqjrq6u++fYsWPdZYLxGffJJ58YSUlJxg9/+EPjww8/NJ588knD4XAYFRUVpr7eYLFE+DAMw/j1r39tjB8/3oiLizMKCwuNDRs2hLtKlnHdddcZbrfbiIuLM0499VTjuuuuM3bu3Nn9+PHjx43bb7/dSE9PN5KSkox/+Zd/Merq6nzOsXv3bmPmzJlGYmKiMXr0aOO+++4zTpw4YfZLiRpvvvmmIanXz0033WQYRtd024ULFxpZWVlGfHy8MX36dGP79u0+5zh06JBxww03GKeccoqRmppq3HzzzUZLS4tPmffee8+45JJLjPj4eOPUU081HnnkEbNeYlTo7z4dO3bMuOqqq4wxY8YYsbGxxoQJE4xbbrml1x9V3KfQ8nd/JBnPPvtsd5lgfca9+eabxrnnnmvExcUZkyZN8rnGSGMzDMMwu7UFAABYV9SP+QAAAJGF8AEAAExF+AAAAKYifAAAAFMRPgAAgKkIHwAAwFSEDwAAYCrCBwAAMBXhAwAAmIrwAQAATEX4AAAApiJ8AAAAU/1/mSerUbXn6MkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and finally let's load the losses and the model back into our jupyter notebook;\n",
    "# remember, we couldn't directly use them in the above training loop, because it\n",
    "# runs in a different, fork'ed process\n",
    "model = LlamaForCausalLM.from_pretrained('lab5_pretrained_model')\n",
    "losses = torch.load('losses.pth')\n",
    "\n",
    "plt.scatter(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e6b5c0-2334-4fff-bacd-16102159515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to play around with this prompt; see what the model can and can't do\n",
    "text_to_complete = 'Lily said the color of the rainbow was very'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb90e712-e136-443e-856f-2b33f27b4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lily said the color of the rainbow was very happy. It was different from the sky that fell from the sky. Lily had seen her friends standing over the ground. They wore different shirts and had different colors.\n",
      "\n",
      "\"Look, Lily, I see a rainbow,\" Tim said. He held the rainbow tightly. He wanted to show it to his friends.\n",
      "\n",
      "\"Wow, Ben, that's a pretty rainbow!\" Lily said. She wanted to show him Ben's sunflower.\n",
      "\n",
      "\"Look, I have a sunflower unicorn!\" Ben said. He looked and waved his hand.\n",
      "\n",
      "Lily smiled and ran to Ben. She was careful not to burn the rainbow. She held her sunflower tight.\n",
      "\n",
      "\"Look, Ben, I found a rainbow unicorn!\" Lily said. She held out her hand. She wanted to touch it.\n",
      "\n",
      "Ben was frightened. He did not like to stay in the rain. It was sad and dirty and cold. He ran to Lily and cried.\n",
      "\n",
      "\"Lily, come back!\" Ben shouted.\n",
      "\n",
      "Mom heard Ben. She ran to Ben. She saw him in the rain. She saw his wet hat bleeding, his green hat, his black dress, his green hat, and his orange face.\n",
      "\n",
      "\"Oh, Lily\n"
     ]
    }
   ],
   "source": [
    "# inference on the model\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device=device)\n",
    "output = pipe(\n",
    "    text_to_complete,\n",
    "    max_new_tokens=256, # number of tokens to generate\n",
    "    do_sample=True, # this gives us a little randomness; set to False for deterministic generation\n",
    ")[0]['generated_text']\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07278ee9-ee37-4b91-a5fd-fcb055092014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a858a384-0981-4f24-ba81-7ae5ebfa5de2",
   "metadata": {},
   "source": [
    "## 5. Scaling up to infinity.. and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e049a-f575-441e-8bb1-47770db09d82",
   "metadata": {},
   "source": [
    "As an exercise, try to do the same for more than 2 GPUs (e.g. for 3). What part of the code needs to change? What stays constant? If I scale up to 10k GPUs, or to 100k GPUs, using the same model, and just data parallelism, what changes? Try to think through these questions while going over the code.\n",
    "\n",
    "Of course, using bigger models, where one model cannot fit into 1 GPU, necessitates different strategies, such as pipeline or tensor parallelism.\n",
    "\n",
    "If you're curious about more, there's [an excellent tutorial from PyTorch on DP](https://pytorch.org/tutorials/intermediate/dist_tuto.html) explaining this communication step between multiple GPUs, a more advanced tutorial on [how to use Distributed Data Parallel in PyTorch](https://pytorch.org/tutorials/beginner/ddp_series_multigpu.html), which abstracts away some of the things we've done above, and there's [a more general tutorial](https://pytorch.org/tutorials/beginner/dist_overview.html) detailing more about what parallelism strategies there are (mainly pipeline and tensor parallelism in PyTorch), and how to use those together with DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4578b-7848-4a81-bb78-f456807174f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
